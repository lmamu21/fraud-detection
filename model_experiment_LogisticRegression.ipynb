{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-27T18:51:14.591588Z",
     "iopub.status.busy": "2025-04-27T18:51:14.591202Z",
     "iopub.status.idle": "2025-04-27T18:51:14.599242Z",
     "shell.execute_reply": "2025-04-27T18:51:14.598211Z",
     "shell.execute_reply.started": "2025-04-27T18:51:14.591557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:51:32.184520Z",
     "iopub.status.busy": "2025-04-27T18:51:32.184202Z",
     "iopub.status.idle": "2025-04-27T18:51:57.376225Z",
     "shell.execute_reply": "2025-04-27T18:51:57.375222Z",
     "shell.execute_reply.started": "2025-04-27T18:51:32.184496Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.13 s, sys: 1.65 s, total: 9.78 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identity_train = pd.read_csv(   \"data/train_identity.csv\")\n",
    "transaction_train = pd.read_csv(\"data/train_transaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:52:10.575536Z",
     "iopub.status.busy": "2025-04-27T18:52:10.574740Z",
     "iopub.status.idle": "2025-04-27T18:52:15.307327Z",
     "shell.execute_reply": "2025-04-27T18:52:15.306460Z",
     "shell.execute_reply.started": "2025-04-27T18:52:10.575504Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 s, sys: 625 ms, total: 3.63 s\n",
      "Wall time: 3.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_transaction = transaction_train.drop(columns=['isFraud'])\n",
    "y = transaction_train['isFraud']\n",
    "\n",
    "X_identity = identity_train.copy()\n",
    "\n",
    "X = pd.merge(X_transaction, X_identity, on='TransactionID', how='left')\n",
    "\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:52:48.660589Z",
     "iopub.status.busy": "2025-04-27T18:52:48.660279Z",
     "iopub.status.idle": "2025-04-27T18:52:48.784605Z",
     "shell.execute_reply": "2025-04-27T18:52:48.783761Z",
     "shell.execute_reply.started": "2025-04-27T18:52:48.660563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "\n",
    "class CustomPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, \n",
    "                 null_threshold=0.6, \n",
    "                 encoding_threshold=7, \n",
    "                 sampling_strategy='none', \n",
    "                 target_ratio=0.5, \n",
    "                 l1_regularization=False, \n",
    "                 l1_C=0.01):\n",
    "        self.null_threshold = null_threshold\n",
    "        self.encoding_threshold = encoding_threshold\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        self.target_ratio = target_ratio\n",
    "        self.l1_regularization = l1_regularization\n",
    "        self.l1_C = l1_C\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # 1. Identify columns to drop\n",
    "        null_frac = X.isnull().mean()\n",
    "        self.cols_to_drop_ = null_frac[null_frac > self.null_threshold].index.tolist()\n",
    "        X = X.drop(columns=self.cols_to_drop_, errors='ignore')\n",
    "        \n",
    "        # 2. Update cat_cols and num_cols after dropping\n",
    "        self.cat_cols_ = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        self.num_cols_ = [col for col in X.columns if col not in self.cat_cols_]\n",
    "        \n",
    "        # 3. Save fill values\n",
    "        self.fill_values_ = {}\n",
    "        for col in self.num_cols_:\n",
    "            self.fill_values_[col] = X[col].median()\n",
    "        for col in self.cat_cols_:\n",
    "            self.fill_values_[col] = X[col].mode(dropna=True)[0]\n",
    "        \n",
    "        # 4. Identify columns to apply WOE\n",
    "        self.onehot_cols_ = []\n",
    "        self.woe_cols_ = []\n",
    "       \n",
    "        for col in self.cat_cols_:\n",
    "            if X[col].nunique() <= self.encoding_threshold:\n",
    "                self.onehot_cols_.append(col)\n",
    "            else:\n",
    "                self.woe_cols_.append(col)\n",
    "        \n",
    "        # 5. Compute WOE mappings for WOE columns\n",
    "        self.woe_maps_ = {}\n",
    "        if y is not None:\n",
    "            for col in self.woe_cols_:\n",
    "                self.woe_maps_[col] = self._compute_woe(X[col], y)\n",
    "\n",
    "        # 6. L1 feature selection\n",
    "        if self.l1_regularization and y is not None:\n",
    "            X_basic = self._basic_clean(X)\n",
    "            model = LogisticRegression(penalty='l1', solver='liblinear', C=self.l1_C, max_iter=1000)\n",
    "            model.fit(X_basic, y)\n",
    "            non_zero_coef = model.coef_[0] != 0\n",
    "            self.selected_features_ = X_basic.columns[non_zero_coef].tolist()\n",
    "        else:\n",
    "            self.selected_features_ = None\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # 1. Drop bad columns\n",
    "        X = X.drop(columns=self.cols_to_drop_, errors='ignore')\n",
    "        \n",
    "        # 2. Fill missing values\n",
    "        for col, fill_value in self.fill_values_.items():\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].fillna(fill_value)\n",
    "        \n",
    "        # 3. Apply WOE encoding for selected columns\n",
    "        for col in self.woe_cols_:\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].map(self.woe_maps_.get(col, {})).fillna(0)\n",
    "\n",
    "        # 4. Apply One-Hot encoding for other columns\n",
    "        X = pd.get_dummies(X, columns=self.onehot_cols_, drop_first=True)\n",
    "        \n",
    "        # 5. If L1 selection, keep only selected features\n",
    "        if self.selected_features_ is not None:\n",
    "            for feature in self.selected_features_:\n",
    "                if feature not in X.columns:\n",
    "                    X[feature] = 0\n",
    "            X = X[self.selected_features_]\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def fit_resample(self, X, y):\n",
    "        \"\"\"Optional resampling after cleaning\"\"\"\n",
    "        X_clean = self.fit(X, y).transform(X)\n",
    "        \n",
    "        if self.sampling_strategy == 'undersample':\n",
    "            fraud = X_clean[y == 1]\n",
    "            legit = X_clean[y == 0]\n",
    "            legit_downsampled = resample(legit, replace=False, \n",
    "                                         n_samples=int(len(fraud) / self.target_ratio - len(fraud)), \n",
    "                                         random_state=42)\n",
    "            X_resampled = pd.concat([fraud, legit_downsampled])\n",
    "            y_resampled = np.array([1]*len(fraud) + [0]*len(legit_downsampled))\n",
    "        \n",
    "        elif self.sampling_strategy == 'oversample':\n",
    "            fraud = X_clean[y == 1]\n",
    "            legit = X_clean[y == 0]\n",
    "            fraud_upsampled = resample(fraud, replace=True, \n",
    "                                       n_samples=int(len(legit) * self.target_ratio / (1 - self.target_ratio)), \n",
    "                                       random_state=42)\n",
    "            X_resampled = pd.concat([fraud_upsampled, legit])\n",
    "            y_resampled = np.array([1]*len(fraud_upsampled) + [0]*len(legit))\n",
    "        \n",
    "        else:\n",
    "            X_resampled = X_clean\n",
    "            y_resampled = y\n",
    "        \n",
    "        return X_resampled, y_resampled\n",
    "    \n",
    "    def _basic_clean(self, X):\n",
    "        X = X.drop(columns=self.cols_to_drop_, errors='ignore')\n",
    "        for col, fill_value in self.fill_values_.items():\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].fillna(fill_value)\n",
    "        X = pd.get_dummies(X, columns=self.cat_cols_, drop_first=True)\n",
    "        return X\n",
    "\n",
    "    def _compute_woe(self, series, y):\n",
    "        df = pd.DataFrame({'feature': series, 'target': y})\n",
    "        grouped = df.groupby('feature')['target']\n",
    "        event = grouped.sum()\n",
    "        non_event = grouped.count() - event\n",
    "        event_rate = (event + 0.5) / event.sum()\n",
    "        non_event_rate = (non_event + 0.5) / non_event.sum()\n",
    "        woe = np.log(event_rate / non_event_rate)\n",
    "        return woe.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:52:53.891864Z",
     "iopub.status.busy": "2025-04-27T18:52:53.891554Z",
     "iopub.status.idle": "2025-04-27T18:52:53.899029Z",
     "shell.execute_reply": "2025-04-27T18:52:53.897104Z",
     "shell.execute_reply.started": "2025-04-27T18:52:53.891838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pre_high_null = CustomPreprocessor(null_threshold=0.8)\n",
    "pre_low_null = CustomPreprocessor(null_threshold=0.5)\n",
    "\n",
    "pre_undersampled = CustomPreprocessor(sampling_strategy='undersample')\n",
    "pre_undersampled_low = CustomPreprocessor(sampling_strategy='undersample', target_ratio=0.3)\n",
    "pre_oversampled = CustomPreprocessor(sampling_strategy='oversample')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:52:59.851004Z",
     "iopub.status.busy": "2025-04-27T18:52:59.850615Z",
     "iopub.status.idle": "2025-04-27T18:53:16.146134Z",
     "shell.execute_reply": "2025-04-27T18:53:16.145095Z",
     "shell.execute_reply.started": "2025-04-27T18:52:59.850978Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.06 s, sys: 8.36 s, total: 15.4 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_high_null = pre_high_null.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.57 s, sys: 5.3 s, total: 9.86 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_low_null = pre_low_null.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.3 s, sys: 6.34 s, total: 11.6 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_undersampled, y_undersampled = pre_undersampled.fit_resample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.37 s, sys: 5.81 s, total: 11.2 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_undersampled_low, y_undersampled_low = pre_undersampled_low.fit_resample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.28 s, sys: 6.09 s, total: 11.4 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_oversampled, y_oversampled = pre_oversampled.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:53:43.465482Z",
     "iopub.status.busy": "2025-04-27T18:53:43.465125Z",
     "iopub.status.idle": "2025-04-27T18:53:43.627267Z",
     "shell.execute_reply": "2025-04-27T18:53:43.626364Z",
     "shell.execute_reply.started": "2025-04-27T18:53:43.465459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def correlation_filter(X, threshold=0.9):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    X_filtered = X.drop(columns=to_drop)\n",
    "    return X_filtered, to_drop\n",
    "\n",
    "def apply_rfe(X, y, n_features=20):\n",
    "    model = LogisticRegression(solver='liblinear', penalty='l2', max_iter=500)\n",
    "    selector = RFE(model, n_features_to_select=n_features)\n",
    "    selector = selector.fit(X, y)\n",
    "    \n",
    "    selected_columns = X.columns[selector.support_].tolist()\n",
    "    X_selected = X[selected_columns]\n",
    "    return X_selected, selected_columns\n",
    "\n",
    "def process_dataset(X, y, corr_threshold=0.7, n_features=15):\n",
    "    X_corr_filtered, dropped_corr = correlation_filter(X, threshold=corr_threshold)\n",
    "    print(\"Correlaction filter finished\")\n",
    "    X_final, selected_cols = apply_rfe(X_corr_filtered, y, n_features=n_features)\n",
    "    print(\"RFE finished\")\n",
    "    return X_final, dropped_corr, selected_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:53:53.927028Z",
     "iopub.status.busy": "2025-04-27T18:53:53.926688Z",
     "iopub.status.idle": "2025-04-27T19:05:55.104451Z",
     "shell.execute_reply": "2025-04-27T19:05:55.102935Z",
     "shell.execute_reply.started": "2025-04-27T18:53:53.927003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlaction filter finished\n",
      "RFE finished\n",
      "CPU times: user 7min 2s, sys: 1.3 s, total: 7min 3s\n",
      "Wall time: 7min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_high_null_final, high_null_dropped_corr, high_null_selected = process_dataset(X_high_null, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlaction filter finished\n",
      "RFE finished\n",
      "CPU times: user 2min 39s, sys: 3.22 s, total: 2min 42s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_low_null_final, low_null_dropped_corr, low_null_selected = process_dataset(X_low_null, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlaction filter finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_undersampled_final, undersampled_dropped_corr, undersampled_selected = process_dataset(X_undersampled, y_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlaction filter finished\n",
      "RFE finished\n",
      "CPU times: user 3min 21s, sys: 53.9 ms, total: 3min 21s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_undersampled_low_final, undersampled_low_dropped_corr, undersampled_low_selected = process_dataset(X_undersampled_low, y_undersampled_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlaction filter finished\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_oversampled_final, oversampled_dropped_corr, oversampled_selected = process_dataset(X_oversampled, y_oversampled)\n",
    "\n",
    "# took to long and kernel crashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlaction filter finished\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_oversampled_final, oversampled_dropped_corr, oversampled_selected = process_dataset(X_oversampled, y_oversampled, n_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T20:32:58.629139Z",
     "iopub.status.busy": "2025-04-27T20:32:58.628760Z",
     "iopub.status.idle": "2025-04-27T20:32:58.876572Z",
     "shell.execute_reply": "2025-04-27T20:32:58.875475Z",
     "shell.execute_reply.started": "2025-04-27T20:32:58.629115Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as lmamu21\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as lmamu21\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"lmamu21/fraud-detection\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"lmamu21/fraud-detection\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository lmamu21/fraud-detection initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository lmamu21/fraud-detection initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "import os\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'lmamu21' \n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '8bc574422c1ba5ebd3c7e16e00460a8560803a94'\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'https://dagshub.com/lmamu21/fraud-detection.mlflow'\n",
    "\n",
    "dagshub.init(repo_owner='lmamu21', repo_name='fraud-detection', mlflow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/machine-learning/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[31m2025/04/28 01:07:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\u001b[31m2025/04/28 01:07:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'LogisticRegression_Model'.\n",
      "2025/04/28 01:07:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LogisticRegression_Model, version 1\n",
      "Created version '1' of model 'LogisticRegression_Model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run LogisticRegression_high_null_threshold at: https://dagshub.com/lmamu21/fraud-detection.mlflow/#/experiments/1/runs/0e9092fdd02c475e920113e6719264d0\n",
      "🧪 View experiment at: https://dagshub.com/lmamu21/fraud-detection.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "mlflow.set_experiment(\"LogisticRegression\")\n",
    "\n",
    "with mlflow.start_run(run_name='LogisticRegression_high_null_threshold'):\n",
    "    mlflow.set_tracking_uri(\"https://dagshub.com/lmamu21/fraud-detection.mlflow\")\n",
    "    \n",
    "    X_validation_clean = pre_high_null.transform(X_validation)\n",
    "    X_validation_clean = X_validation_clean.reindex(columns=X_high_null_final.columns, fill_value=0)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    model.fit(X_high_null_final, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_validation_clean)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_validation, y_pred)\n",
    "    class_report = classification_report(y_validation, y_pred)\n",
    "    y_pred_proba = model.predict_proba(X_validation_clean)[:, 1] \n",
    "    roc_auc = roc_auc_score(y_validation, y_pred_proba)\n",
    "\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    \n",
    "    preprocessor_params = {\n",
    "        'null_threshold': 0.8,\n",
    "        'encoding_threshold': 7,\n",
    "        'sampling_strategy': 'none',\n",
    "        'l1_regularization': False        \n",
    "    }\n",
    "\n",
    "    rfe_params = {\n",
    "        'n_features_to_select': 15\n",
    "    }\n",
    "\n",
    "    correlation_filter_params = {\n",
    "        'corr_threshold': 0.7\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(preprocessor_params)  \n",
    "    mlflow.log_params(rfe_params)  \n",
    "    mlflow.log_params(correlation_filter_params)  \n",
    "\n",
    "    with open(\"confusion_matrix.txt\", \"w\") as f:\n",
    "        f.write(str(conf_matrix))\n",
    "    mlflow.log_artifact(\"confusion_matrix.txt\")\n",
    "    \n",
    "    with open(\"classification_report.txt\", \"w\") as f:\n",
    "        f.write(class_report)\n",
    "    mlflow.log_artifact(\"classification_report.txt\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model_high_null_threshold\")\n",
    "    \n",
    "    mlflow.log_param(\"solver\", model.solver)\n",
    "    mlflow.log_param(\"C\", model.C)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model_high_null_threshold\")\n",
    "    \n",
    "    # Register the model in the Model Registry\n",
    "    model_uri = f\"runs:/{mlflow.active_run().info.run_id}/logistic_regression_model_high_null_threshold\"\n",
    "    mlflow.register_model(model_uri, \"logistic_regression_model_high_null_threshold\")\n",
    "\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/machine-learning/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[31m2025/04/28 01:26:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\u001b[31m2025/04/28 01:26:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'logistic_regression_model_low_null_threshold'.\n",
      "2025/04/28 01:26:51 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: logistic_regression_model_low_null_threshold, version 1\n",
      "Created version '1' of model 'logistic_regression_model_low_null_threshold'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run LogisticRegression_low_null_threshold at: https://dagshub.com/lmamu21/fraud-detection.mlflow/#/experiments/1/runs/580590c3e4e44eb79815ad46bcfdb4a9\n",
      "🧪 View experiment at: https://dagshub.com/lmamu21/fraud-detection.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "mlflow.set_experiment(\"LogisticRegression\")\n",
    "\n",
    "with mlflow.start_run(run_name='LogisticRegression_low_null_threshold'):\n",
    "    mlflow.set_tracking_uri(\"https://dagshub.com/lmamu21/fraud-detection.mlflow\")\n",
    "    \n",
    "    X_validation_clean = pre_low_null.transform(X_validation)\n",
    "    X_validation_clean = X_validation_clean.reindex(columns=X_low_null_final.columns, fill_value=0)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    model.fit(X_low_null_final, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_validation_clean)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_validation, y_pred)\n",
    "    class_report = classification_report(y_validation, y_pred)\n",
    "    y_pred_proba = model.predict_proba(X_validation_clean)[:, 1] \n",
    "    roc_auc = roc_auc_score(y_validation, y_pred_proba)\n",
    "\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    \n",
    "    preprocessor_params = {\n",
    "        'null_threshold': 0.5,\n",
    "        'encoding_threshold': 7,\n",
    "        'sampling_strategy': 'none',\n",
    "        'l1_regularization': False        \n",
    "    }\n",
    "\n",
    "    rfe_params = {\n",
    "        'n_features_to_select': 15\n",
    "    }\n",
    "\n",
    "    correlation_filter_params = {\n",
    "        'corr_threshold': 0.7\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(preprocessor_params)  \n",
    "    mlflow.log_params(rfe_params)  \n",
    "    mlflow.log_params(correlation_filter_params)  \n",
    "\n",
    "    with open(\"confusion_matrix.txt\", \"w\") as f:\n",
    "        f.write(str(conf_matrix))\n",
    "    mlflow.log_artifact(\"confusion_matrix.txt\")\n",
    "    \n",
    "    with open(\"classification_report.txt\", \"w\") as f:\n",
    "        f.write(class_report)\n",
    "    mlflow.log_artifact(\"classification_report.txt\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model_low_null_threshold\")\n",
    "    \n",
    "    mlflow.log_param(\"solver\", model.solver)\n",
    "    mlflow.log_param(\"C\", model.C)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model_low_null_threshold\")\n",
    "    \n",
    "    # Register the model in the Model Registry\n",
    "    model_uri = f\"runs:/{mlflow.active_run().info.run_id}/logistic_regression_model_low_null_threshold\"\n",
    "    mlflow.register_model(model_uri, \"logistic_regression_model_low_null_threshold\")\n",
    "\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/28 01:50:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\u001b[31m2025/04/28 01:50:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'logistic_regression_model_undersampled' already exists. Creating a new version of this model...\n",
      "2025/04/28 01:50:38 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: logistic_regression_model_undersampled, version 2\n",
      "Created version '2' of model 'logistic_regression_model_undersampled'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run LogisticRegression_undersampled at: https://dagshub.com/lmamu21/fraud-detection.mlflow/#/experiments/1/runs/cc8e72b37e5d431cbdf91fdfebb783fe\n",
      "🧪 View experiment at: https://dagshub.com/lmamu21/fraud-detection.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "mlflow.set_experiment(\"LogisticRegression\")\n",
    "\n",
    "with mlflow.start_run(run_name='LogisticRegression_undersampled'):\n",
    "    mlflow.set_tracking_uri(\"https://dagshub.com/lmamu21/fraud-detection.mlflow\")\n",
    "    \n",
    "    X_validation_clean = pre_undersampled.transform(X_validation)\n",
    "    X_validation_clean = X_validation_clean.reindex(columns=X_undersampled_final.columns, fill_value=0)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    model.fit(X_undersampled_final, y_undersampled)\n",
    "\n",
    "    y_pred = model.predict(X_validation_clean)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_validation, y_pred)\n",
    "    class_report = classification_report(y_validation, y_pred)\n",
    "    y_pred_proba = model.predict_proba(X_validation_clean)[:, 1] \n",
    "    roc_auc = roc_auc_score(y_validation, y_pred_proba)\n",
    "\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    \n",
    "    preprocessor_params = {\n",
    "        'null_threshold': 0.6,\n",
    "        'encoding_threshold': 7,\n",
    "        'sampling_strategy': 'undersampling',\n",
    "        'l1_regularization': False        \n",
    "    }\n",
    "\n",
    "    rfe_params = {\n",
    "        'n_features_to_select': 15\n",
    "    }\n",
    "\n",
    "    correlation_filter_params = {\n",
    "        'corr_threshold': 0.7\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(preprocessor_params)  \n",
    "    mlflow.log_params(rfe_params)  \n",
    "    mlflow.log_params(correlation_filter_params)  \n",
    "\n",
    "    with open(\"confusion_matrix.txt\", \"w\") as f:\n",
    "        f.write(str(conf_matrix))\n",
    "    mlflow.log_artifact(\"confusion_matrix.txt\")\n",
    "    \n",
    "    with open(\"classification_report.txt\", \"w\") as f:\n",
    "        f.write(class_report)\n",
    "    mlflow.log_artifact(\"classification_report.txt\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model_undersampled\")\n",
    "    \n",
    "    mlflow.log_param(\"solver\", model.solver)\n",
    "    mlflow.log_param(\"C\", model.C)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model_undersampled\")\n",
    "    \n",
    "    # Register the model in the Model Registry\n",
    "    model_uri = f\"runs:/{mlflow.active_run().info.run_id}/logistic_regression_model_undersampled\"\n",
    "    mlflow.register_model(model_uri, \"logistic_regression_model_undersampled\")\n",
    "\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/28 02:04:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\u001b[31m2025/04/28 02:04:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'logistic_regression_model_undersampled_low'.\n",
      "2025/04/28 02:04:10 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: logistic_regression_model_undersampled_low, version 1\n",
      "Created version '1' of model 'logistic_regression_model_undersampled_low'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run LogisticRegression_undersampled at: https://dagshub.com/lmamu21/fraud-detection.mlflow/#/experiments/1/runs/ba6c76cdeb114b0298b26f7adfd26823\n",
      "🧪 View experiment at: https://dagshub.com/lmamu21/fraud-detection.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "mlflow.set_experiment(\"LogisticRegression\")\n",
    "\n",
    "with mlflow.start_run(run_name='LogisticRegression_undersampled'):\n",
    "    mlflow.set_tracking_uri(\"https://dagshub.com/lmamu21/fraud-detection.mlflow\")\n",
    "    \n",
    "    X_validation_clean = pre_undersampled_low.transform(X_validation)\n",
    "    X_validation_clean = X_validation_clean.reindex(columns=X_undersampled_low_final.columns, fill_value=0)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    model.fit(X_undersampled_low_final, y_undersampled_low)\n",
    "\n",
    "    y_pred = model.predict(X_validation_clean)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_validation, y_pred)\n",
    "    class_report = classification_report(y_validation, y_pred)\n",
    "    y_pred_proba = model.predict_proba(X_validation_clean)[:, 1] \n",
    "    roc_auc = roc_auc_score(y_validation, y_pred_proba)\n",
    "\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    \n",
    "    preprocessor_params = {\n",
    "        'null_threshold': 0.6,\n",
    "        'encoding_threshold': 7,\n",
    "        'sampling_strategy': 'undersampling',\n",
    "        'target_ratio': 0.3,\n",
    "        'l1_regularization': False        \n",
    "    }\n",
    "\n",
    "    rfe_params = {\n",
    "        'n_features_to_select': 15\n",
    "    }\n",
    "\n",
    "    correlation_filter_params = {\n",
    "        'corr_threshold': 0.7\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(preprocessor_params)  \n",
    "    mlflow.log_params(rfe_params)  \n",
    "    mlflow.log_params(correlation_filter_params)  \n",
    "\n",
    "    with open(\"confusion_matrix.txt\", \"w\") as f:\n",
    "        f.write(str(conf_matrix))\n",
    "    mlflow.log_artifact(\"confusion_matrix.txt\")\n",
    "    \n",
    "    with open(\"classification_report.txt\", \"w\") as f:\n",
    "        f.write(class_report)\n",
    "    mlflow.log_artifact(\"classification_report.txt\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model_undersampled_low\")\n",
    "    \n",
    "    mlflow.log_param(\"solver\", model.solver)\n",
    "    mlflow.log_param(\"C\", model.C)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model_undersampled_low\")\n",
    "    \n",
    "    # Register the model in the Model Registry\n",
    "    model_uri = f\"runs:/{mlflow.active_run().info.run_id}/logistic_regression_model_undersampled_low\"\n",
    "    mlflow.register_model(model_uri, \"logistic_regression_model_undersampled_low\")\n",
    "\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "mlflow.set_experiment(\"LogisticRegression\")\n",
    "\n",
    "# not actually run, because oversampled data took too much time to process\n",
    "\n",
    "with mlflow.start_run(run_name='LogisticRegression_oversampled'):\n",
    "    mlflow.set_tracking_uri(\"https://dagshub.com/lmamu21/fraud-detection.mlflow\")\n",
    "    \n",
    "    X_validation_clean = pre_oversampled.transform(X_validation)\n",
    "    X_validation_clean = X_validation_clean.reindex(columns=X_oversampled.columns, fill_value=0)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    model.fit(X_oversampled, y_oversampled)\n",
    "\n",
    "    y_pred = model.predict(X_validation_clean)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_validation, y_pred)\n",
    "    class_report = classification_report(y_validation, y_pred)\n",
    "    y_pred_proba = model.predict_proba(X_validation_clean)[:, 1] \n",
    "    roc_auc = roc_auc_score(y_validation, y_pred_proba)\n",
    "\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    \n",
    "    preprocessor_params = {\n",
    "        'null_threshold': 0.6,\n",
    "        'encoding_threshold': 7,\n",
    "        'sampling_strategy': 'undersampling',\n",
    "        'target_ratio': 0.3,\n",
    "        'l1_regularization': False        \n",
    "    }\n",
    "\n",
    "    rfe_params = {\n",
    "        'n_features_to_select': 15\n",
    "    }\n",
    "\n",
    "    correlation_filter_params = {\n",
    "        'corr_threshold': 0.7\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(preprocessor_params)  \n",
    "    mlflow.log_params(rfe_params)  \n",
    "    mlflow.log_params(correlation_filter_params)  \n",
    "\n",
    "    with open(\"confusion_matrix.txt\", \"w\") as f:\n",
    "        f.write(str(conf_matrix))\n",
    "    mlflow.log_artifact(\"confusion_matrix.txt\")\n",
    "    \n",
    "    with open(\"classification_report.txt\", \"w\") as f:\n",
    "        f.write(class_report)\n",
    "    mlflow.log_artifact(\"classification_report.txt\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model_undersampled_low\")\n",
    "    \n",
    "    mlflow.log_param(\"solver\", model.solver)\n",
    "    mlflow.log_param(\"C\", model.C)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model_undersampled_low\")\n",
    "    \n",
    "    # Register the model in the Model Registry\n",
    "    model_uri = f\"runs:/{mlflow.active_run().info.run_id}/logistic_regression_model_undersampled_low\"\n",
    "    mlflow.register_model(model_uri, \"logistic_regression_model_undersampled_low\")\n",
    "\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 568274,
     "sourceId": 14242,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
