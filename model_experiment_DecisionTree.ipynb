{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:01:45.281486Z","iopub.execute_input":"2025-04-29T08:01:45.282493Z","iopub.status.idle":"2025-04-29T08:01:45.291002Z","shell.execute_reply.started":"2025-04-29T08:01:45.282458Z","shell.execute_reply":"2025-04-29T08:01:45.289633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nidentity_train = pd.read_csv(   \"/kaggle/input/ieee-fraud-detection/train_identity.csv\")\ntransaction_train = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_transaction.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:01:46.859120Z","iopub.execute_input":"2025-04-29T08:01:46.860028Z","iopub.status.idle":"2025-04-29T08:02:18.063559Z","shell.execute_reply.started":"2025-04-29T08:01:46.859987Z","shell.execute_reply":"2025-04-29T08:02:18.062606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import train_test_split\n\nX_transaction = transaction_train.drop(columns=['isFraud'])\ny = transaction_train['isFraud']\n\nX_identity = identity_train.copy()\n\nX = pd.merge(X_transaction, X_identity, on='TransactionID', how='left')\n\n\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:02:33.283091Z","iopub.execute_input":"2025-04-29T08:02:33.283424Z","iopub.status.idle":"2025-04-29T08:02:42.262173Z","shell.execute_reply.started":"2025-04-29T08:02:33.283394Z","shell.execute_reply":"2025-04-29T08:02:42.260328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.utils import resample\n\nclass CustomPreprocessor(BaseEstimator, TransformerMixin):\n    def __init__(self, \n                 null_threshold=0.6, \n                 encoding_threshold=7, \n                 sampling_strategy='none', \n                 target_ratio=0.5, \n                 l1_regularization=False, \n                 l1_C=0.01):\n        self.null_threshold = null_threshold\n        self.encoding_threshold = encoding_threshold\n        self.sampling_strategy = sampling_strategy\n        self.target_ratio = target_ratio\n        self.l1_regularization = l1_regularization\n        self.l1_C = l1_C\n        \n    def fit(self, X, y=None):\n        X = X.copy()\n        \n        # 1. Identify columns to drop\n        null_frac = X.isnull().mean()\n        self.cols_to_drop_ = null_frac[null_frac > self.null_threshold].index.tolist()\n        X = X.drop(columns=self.cols_to_drop_, errors='ignore')\n        \n        # 2. Update cat_cols and num_cols after dropping\n        self.cat_cols_ = X.select_dtypes(include=['object', 'category']).columns.tolist()\n        self.num_cols_ = [col for col in X.columns if col not in self.cat_cols_]\n        \n        # 3. Save fill values\n        self.fill_values_ = {}\n        for col in self.num_cols_:\n            self.fill_values_[col] = X[col].median()\n        for col in self.cat_cols_:\n            self.fill_values_[col] = X[col].mode(dropna=True)[0]\n        \n        # 4. Identify columns to apply WOE\n        self.onehot_cols_ = []\n        self.woe_cols_ = []\n       \n        for col in self.cat_cols_:\n            if X[col].nunique() <= self.encoding_threshold:\n                self.onehot_cols_.append(col)\n            else:\n                self.woe_cols_.append(col)\n        \n        # 5. Compute WOE mappings for WOE columns\n        self.woe_maps_ = {}\n        if y is not None:\n            for col in self.woe_cols_:\n                self.woe_maps_[col] = self._compute_woe(X[col], y)\n\n        # 6. L1 feature selection\n        if self.l1_regularization and y is not None:\n            X_basic = self._basic_clean(X)\n            model = LogisticRegression(penalty='l1', solver='liblinear', C=self.l1_C, max_iter=1000)\n            model.fit(X_basic, y)\n            non_zero_coef = model.coef_[0] != 0\n            self.selected_features_ = X_basic.columns[non_zero_coef].tolist()\n        else:\n            self.selected_features_ = None\n\n        return self\n\n    def transform(self, X):\n        X = X.copy()\n        \n        # 1. Drop bad columns\n        X = X.drop(columns=self.cols_to_drop_, errors='ignore')\n        \n        # 2. Fill missing values\n        for col, fill_value in self.fill_values_.items():\n            if col in X.columns:\n                X[col] = X[col].fillna(fill_value)\n        \n        # 3. Apply WOE encoding for selected columns\n        for col in self.woe_cols_:\n            if col in X.columns:\n                X[col] = X[col].map(self.woe_maps_.get(col, {})).fillna(0)\n\n        # 4. Apply One-Hot encoding for other columns\n        X = pd.get_dummies(X, columns=self.onehot_cols_, drop_first=True)\n        \n        # 5. If L1 selection, keep only selected features\n        if self.selected_features_ is not None:\n            for feature in self.selected_features_:\n                if feature not in X.columns:\n                    X[feature] = 0\n            X = X[self.selected_features_]\n        \n        return X\n\n    def fit_resample(self, X, y):\n        \"\"\"Optional resampling after cleaning\"\"\"\n        X_clean = self.fit(X, y).transform(X)\n        \n        if self.sampling_strategy == 'undersample':\n            fraud = X_clean[y == 1]\n            legit = X_clean[y == 0]\n            legit_downsampled = resample(legit, replace=False, \n                                         n_samples=int(len(fraud) / self.target_ratio - len(fraud)), \n                                         random_state=42)\n            X_resampled = pd.concat([fraud, legit_downsampled])\n            y_resampled = np.array([1]*len(fraud) + [0]*len(legit_downsampled))\n        \n        elif self.sampling_strategy == 'undersample':\n            fraud = X_clean[y == 1]\n            legit = X_clean[y == 0]\n            fraud_upsampled = resample(fraud, replace=True, \n                                       n_samples=int(len(legit) * self.target_ratio / (1 - self.target_ratio)), \n                                       random_state=42)\n            X_resampled = pd.concat([fraud_upsampled, legit])\n            y_resampled = np.array([1]*len(fraud_upsampled) + [0]*len(legit))\n        \n        else:\n            X_resampled = X_clean\n            y_resampled = y\n        \n        return X_resampled, y_resampled\n    \n    def _basic_clean(self, X):\n        X = X.drop(columns=self.cols_to_drop_, errors='ignore')\n        for col, fill_value in self.fill_values_.items():\n            if col in X.columns:\n                X[col] = X[col].fillna(fill_value)\n        X = pd.get_dummies(X, columns=self.cat_cols_, drop_first=True)\n        return X\n\n    def _compute_woe(self, series, y):\n        df = pd.DataFrame({'feature': series, 'target': y})\n        grouped = df.groupby('feature')['target']\n        event = grouped.sum()\n        non_event = grouped.count() - event\n        event_rate = (event + 0.5) / event.sum()\n        non_event_rate = (non_event + 0.5) / non_event.sum()\n        woe = np.log(event_rate / non_event_rate)\n        return woe.to_dict()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:02:43.602381Z","iopub.execute_input":"2025-04-29T08:02:43.603665Z","iopub.status.idle":"2025-04-29T08:02:43.705950Z","shell.execute_reply.started":"2025-04-29T08:02:43.603596Z","shell.execute_reply":"2025-04-29T08:02:43.704914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pre_high_null = CustomPreprocessor(null_threshold=0.8)\npre_low_null = CustomPreprocessor(null_threshold=0.2)\n\npre_undersampled = CustomPreprocessor(sampling_strategy='undersample')\npre_undersampled_low = CustomPreprocessor(sampling_strategy='undersample', target_ratio=0.3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:02:47.869060Z","iopub.execute_input":"2025-04-29T08:02:47.869448Z","iopub.status.idle":"2025-04-29T08:02:47.874752Z","shell.execute_reply.started":"2025-04-29T08:02:47.869417Z","shell.execute_reply":"2025-04-29T08:02:47.873599Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n\ndef correlation_filter(X, threshold=0.9):\n    corr_matrix = X.corr().abs()\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n    \n    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n    X_filtered = X.drop(columns=to_drop)\n    return X_filtered, to_drop\n\ndef apply_rfe(X, y, n_features=20):\n    model = LogisticRegression(solver='liblinear', penalty='l2', max_iter=200)\n    selector = RFE(model, n_features_to_select=n_features, )\n    selector = selector.fit(X, y)\n    \n    selected_columns = X.columns[selector.support_].tolist()\n    X_selected = X[selected_columns]\n    return X_selected, selected_columns\n\ndef process_dataset(X, y, corr_threshold=0.7, n_features=15):\n    X_corr_filtered, dropped_corr = correlation_filter(X, threshold=corr_threshold)\n    print(\"Correlaction filter finished\")\n    X_final, selected_cols = apply_rfe(X_corr_filtered, y, n_features=n_features)\n    print(\"RFE finished\")\n    return X_final, dropped_corr, selected_cols\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:02:50.453151Z","iopub.execute_input":"2025-04-29T08:02:50.453496Z","iopub.status.idle":"2025-04-29T08:02:50.537670Z","shell.execute_reply.started":"2025-04-29T08:02:50.453467Z","shell.execute_reply":"2025-04-29T08:02:50.536507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nprint(\"transforming undersampled\")\nX_undersampled, y_undersampled = pre_undersampled.fit_resample(X_train, y_train)\nprint(\"transforming undersampled_low\")\nX_undersampled_low, y_undersampled_low = pre_undersampled_low.fit_resample(X_train, y_train)\n\nprint(\"transforming high_null\")\nX_high_null = pre_high_null.fit_transform(X_train, y_train)\nprint(\"transforming low_null\")\nX_low_null = pre_low_null.fit_transform(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:02:53.402994Z","iopub.execute_input":"2025-04-29T08:02:53.403352Z","iopub.status.idle":"2025-04-29T08:03:47.071783Z","shell.execute_reply.started":"2025-04-29T08:02:53.403327Z","shell.execute_reply":"2025-04-29T08:03:47.070593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nprint(\"Processing X_undersampled\")\nX_undersampled_final, undersampled_dropped_corr, undersampled_selected = process_dataset(X_undersampled, y_undersampled)\n\nprint(\"Processing X_undersampled_low\")\nX_undersampled_low_final, undersampled_low_dropped_corr, undersampled_low_selected = process_dataset(X_undersampled_low, y_undersampled_low)\n\nprint(\"Processing X_high_null\")\nX_high_null_final, high_null_dropped_corr, high_null_selected = process_dataset(X_high_null, y_train)\n\nprint(\"Processing X_low_null\")\nX_low_null_final, low_null_dropped_corr, low_null_selected = process_dataset(X_low_null, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:03:54.215021Z","iopub.execute_input":"2025-04-29T08:03:54.215333Z","iopub.status.idle":"2025-04-29T08:26:45.331692Z","shell.execute_reply.started":"2025-04-29T08:03:54.215311Z","shell.execute_reply":"2025-04-29T08:26:45.328726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import dagshub\nimport os\nos.environ['MLFLOW_TRACKING_USERNAME'] = 'lmamu21' \nos.environ['MLFLOW_TRACKING_PASSWORD'] = '8bc574422c1ba5ebd3c7e16e00460a8560803a94'\nos.environ['MLFLOW_TRACKING_URI'] = 'https://dagshub.com/lmamu21/fraud-detection.mlflow'\n\ndagshub.init(repo_owner='lmamu21', repo_name='fraud-detection', mlflow=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:30:47.979016Z","iopub.execute_input":"2025-04-29T08:30:47.979359Z","iopub.status.idle":"2025-04-29T08:30:56.580942Z","shell.execute_reply.started":"2025-04-29T08:30:47.979335Z","shell.execute_reply":"2025-04-29T08:30:56.579191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install dagshub mlflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:27:15.407445Z","iopub.execute_input":"2025-04-29T08:27:15.408265Z","iopub.status.idle":"2025-04-29T08:27:38.057747Z","shell.execute_reply.started":"2025-04-29T08:27:15.408228Z","shell.execute_reply":"2025-04-29T08:27:38.056286Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score\n\n\n\nmlflow.set_experiment(\"DecisionTree\")\n\nwith mlflow.start_run(run_name=\"DecisionTree_low_null\"):\n    X_validation_clean = pre_low_null.transform(X_validation)\n    X_validation_clean = X_validation_clean.reindex(columns=X_low_null_final.columns, fill_value=0)\n    \n    model = DecisionTreeClassifier(\n        max_depth=5,\n        min_samples_split=10,\n        random_state=42\n    )\n    \n    model.fit(X_low_null_final, y_train)\n    \n    y_pred = model.predict(X_validation_clean)\n\n    conf_matrix = confusion_matrix(y_validation, y_pred)\n    class_report = classification_report(y_validation, y_pred)\n    y_pred_proba = model.predict_proba(X_validation_clean)[:, 1]  # Get probabilities for the positive class\n    roc_auc = roc_auc_score(y_validation, y_pred_proba)\n    mlflow.log_metric(\"roc_auc\", roc_auc)\n\n    preprocessor_params = {\n        'null_threshold': 0.2,\n        'encoding_threshold': 7,\n        'sampling_strategy': 'none',\n        'l1_regularization': False,\n        'C': 1\n    }\n\n    feat_selection_params = {\n        'corr_threshold': 0.7,\n        'n_features_to_select': 15,\n    }\n\n    mlflow.log_params(preprocessor_params)\n    mlflow.log_params(feat_selection_params)\n    \n    mlflow.log_param(\"max_depth\", 5)\n    mlflow.log_param(\"min_samples_split\", 10)\n    mlflow.log_param(\"random_state\", 42)\n\n    acc = accuracy_score(y_validation, y_pred)\n    prec = precision_score(y_validation, y_pred)\n    rec = recall_score(y_validation, y_pred)\n    f1 = f1_score(y_validation, y_pred)\n    \n    mlflow.log_metric(\"accuracy\", acc)\n    mlflow.log_metric(\"precision\", prec)\n    mlflow.log_metric(\"recall\", rec)\n    mlflow.log_metric(\"f1_score\", f1)\n\n    \n \n    mlflow.sklearn.log_model(model, artifact_path=\"decision_tree_model_low_null\")\n\n    mlflow.end_run()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:49:53.746178Z","iopub.execute_input":"2025-04-29T08:49:53.746596Z","iopub.status.idle":"2025-04-29T08:50:07.858143Z","shell.execute_reply.started":"2025-04-29T08:49:53.746567Z","shell.execute_reply":"2025-04-29T08:50:07.856962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score\n\n\n\nmlflow.set_experiment(\"DecisionTree\")\n\nwith mlflow.start_run(run_name=\"DecisionTree_high_null\"):\n    X_validation_clean = pre_high_null.transform(X_validation)\n    X_validation_clean = X_validation_clean.reindex(columns=X_high_null_final.columns, fill_value=0)\n    \n    model = DecisionTreeClassifier(\n        max_depth=5,\n        min_samples_split=10,\n        random_state=42\n    )\n    \n    model.fit(X_high_null_final, y_train)\n    \n    y_pred = model.predict(X_validation_clean)\n\n    conf_matrix = confusion_matrix(y_validation, y_pred)\n    class_report = classification_report(y_validation, y_pred)\n    y_pred_proba = model.predict_proba(X_validation_clean)[:, 1]  # Get probabilities for the positive class\n    roc_auc = roc_auc_score(y_validation, y_pred_proba)\n    mlflow.log_metric(\"roc_auc\", roc_auc)\n\n    preprocessor_params = {\n        'null_threshold': 0.8,\n        'encoding_threshold': 7,\n        'sampling_strategy': 'none',\n        'l1_regularization': False,\n        'C': 1\n    }\n\n    feat_selection_params = {\n        'corr_threshold': 0.7,\n        'n_features_to_select': 15,\n    }\n\n    mlflow.log_params(preprocessor_params)\n    mlflow.log_params(feat_selection_params)\n    \n    mlflow.log_param(\"max_depth\", 5)\n    mlflow.log_param(\"min_samples_split\", 10)\n    mlflow.log_param(\"random_state\", 42)\n\n    acc = accuracy_score(y_validation, y_pred)\n    prec = precision_score(y_validation, y_pred)\n    rec = recall_score(y_validation, y_pred)\n    f1 = f1_score(y_validation, y_pred)\n    \n    mlflow.log_metric(\"accuracy\", acc)\n    mlflow.log_metric(\"precision\", prec)\n    mlflow.log_metric(\"recall\", rec)\n    mlflow.log_metric(\"f1_score\", f1)\n\n    \n \n    mlflow.sklearn.log_model(model, artifact_path=\"decision_tree_model_high_null\")\n\n    mlflow.end_run()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:51:26.655425Z","iopub.execute_input":"2025-04-29T08:51:26.655862Z","iopub.status.idle":"2025-04-29T08:51:40.416112Z","shell.execute_reply.started":"2025-04-29T08:51:26.655836Z","shell.execute_reply":"2025-04-29T08:51:40.414841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score\n\n\n\nmlflow.set_experiment(\"DecisionTree\")\n\nwith mlflow.start_run(run_name=\"DecisionTree_undersampled\"):\n    X_validation_clean = pre_undersampled.transform(X_validation)\n    X_validation_clean = X_validation_clean.reindex(columns=X_undersampled_final.columns, fill_value=0)\n    \n    model = DecisionTreeClassifier(\n        max_depth=5,\n        min_samples_split=10,\n        random_state=42\n    )\n    \n    model.fit(X_undersampled_final, y_undersampled)\n    \n    y_pred = model.predict(X_validation_clean)\n\n    conf_matrix = confusion_matrix(y_validation, y_pred)\n    class_report = classification_report(y_validation, y_pred)\n    y_pred_proba = model.predict_proba(X_validation_clean)[:, 1]  # Get probabilities for the positive class\n    roc_auc = roc_auc_score(y_validation, y_pred_proba)\n    mlflow.log_metric(\"roc_auc\", roc_auc)\n\n    preprocessor_params = {\n        'null_threshold': 0.6,\n        'encoding_threshold': 7,\n        'sampling_strategy': 'undersampling',\n        'l1_regularization': False,\n    }\n\n    feat_selection_params = {\n        'corr_threshold': 0.7,\n        'n_features_to_select': 15,\n    }\n\n    mlflow.log_params(preprocessor_params)\n    mlflow.log_params(feat_selection_params)\n    \n    mlflow.log_param(\"max_depth\", 5)\n    mlflow.log_param(\"min_samples_split\", 10)\n    mlflow.log_param(\"random_state\", 42)\n\n    acc = accuracy_score(y_validation, y_pred)\n    prec = precision_score(y_validation, y_pred)\n    rec = recall_score(y_validation, y_pred)\n    f1 = f1_score(y_validation, y_pred)\n    \n    mlflow.log_metric(\"accuracy\", acc)\n    mlflow.log_metric(\"precision\", prec)\n    mlflow.log_metric(\"recall\", rec)\n    mlflow.log_metric(\"f1_score\", f1)\n\n    \n \n    mlflow.sklearn.log_model(model, artifact_path=\"decision_tree_model_undersampled\")\n\n    mlflow.end_run()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:56:25.429890Z","iopub.execute_input":"2025-04-29T08:56:25.430835Z","iopub.status.idle":"2025-04-29T08:56:36.440938Z","shell.execute_reply.started":"2025-04-29T08:56:25.430797Z","shell.execute_reply":"2025-04-29T08:56:36.439596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport mlflow\nimport mlflow.sklearn\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score\n\n\n\nmlflow.set_experiment(\"DecisionTree\")\n\nwith mlflow.start_run(run_name=\"DecisionTree_undersampled_low\"):\n    X_validation_clean = pre_undersampled_low.transform(X_validation)\n    X_validation_clean = X_validation_clean.reindex(columns=X_undersampled_low_final.columns, fill_value=0)\n    \n    model = DecisionTreeClassifier(\n        max_depth=5,\n        min_samples_split=10,\n        random_state=42\n    )\n    \n    model.fit(X_undersampled_low_final, y_undersampled_low)\n    \n    y_pred = model.predict(X_validation_clean)\n\n    conf_matrix = confusion_matrix(y_validation, y_pred)\n    class_report = classification_report(y_validation, y_pred)\n    y_pred_proba = model.predict_proba(X_validation_clean)[:, 1]  # Get probabilities for the positive class\n    roc_auc = roc_auc_score(y_validation, y_pred_proba)\n    mlflow.log_metric(\"roc_auc\", roc_auc)\n\n    preprocessor_params = {\n        'null_threshold': 0.6,\n        'encoding_threshold': 7,\n        'sampling_strategy': 'undersampling',\n        'target_ratio': 0.3,\n        'l1_regularization': False,\n    }\n\n    feat_selection_params = {\n        'corr_threshold': 0.7,\n        'n_features_to_select': 15,\n    }\n\n    mlflow.log_params(preprocessor_params)\n    mlflow.log_params(feat_selection_params)\n    \n    mlflow.log_param(\"max_depth\", 5)\n    mlflow.log_param(\"min_samples_split\", 10)\n    mlflow.log_param(\"random_state\", 42)\n\n    acc = accuracy_score(y_validation, y_pred)\n    prec = precision_score(y_validation, y_pred)\n    rec = recall_score(y_validation, y_pred)\n    f1 = f1_score(y_validation, y_pred)\n    \n    mlflow.log_metric(\"accuracy\", acc)\n    mlflow.log_metric(\"precision\", prec)\n    mlflow.log_metric(\"recall\", rec)\n    mlflow.log_metric(\"f1_score\", f1)\n\n    \n \n    mlflow.sklearn.log_model(model, artifact_path=\"decision_tree_model_undersampled_low\")\n\n    mlflow.end_run()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T08:58:13.375166Z","iopub.execute_input":"2025-04-29T08:58:13.375676Z","iopub.status.idle":"2025-04-29T08:58:24.056283Z","shell.execute_reply.started":"2025-04-29T08:58:13.375644Z","shell.execute_reply":"2025-04-29T08:58:24.054915Z"}},"outputs":[],"execution_count":null}]}